name: R2 Connection Test

on:
  workflow_dispatch:   # 手动触发测试
  # schedule:          # 如果需要定时也可以开启
  #   - cron: '0 6 * * *'

jobs:
  test-r2:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout repository
        uses: actions/checkout@v3

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: 3.11

      - name: Install boto3
        run: pip install boto3

      - name: List objects in R2 bucket
        env:
          R2_ACCESS_KEY_ID: ${{ secrets.R2_ACCESS_KEY_ID }}
          R2_SECRET_ACCESS_KEY: ${{ secrets.R2_SECRET_ACCESS_KEY }}
          R2_BUCKET_NAME: ${{ secrets.R2_BUCKET_NAME }}
          R2_ACCOUNT_ID: ${{ secrets.R2_ACCOUNT_ID }}
        run: |
          python - <<EOF
          import os
          import boto3
          from botocore.exceptions import ClientError

          R2_ACCESS_KEY_ID = os.environ['R2_ACCESS_KEY_ID']
          R2_SECRET_ACCESS_KEY = os.environ['R2_SECRET_ACCESS_KEY']
          R2_BUCKET_NAME = os.environ['R2_BUCKET_NAME']
          R2_ACCOUNT_ID = os.environ['R2_ACCOUNT_ID']

          # 创建 R2 S3 客户端
          client = boto3.client(
              's3',
              region_name='auto',
              endpoint_url=f'https://{R2_ACCOUNT_ID}.r2.cloudflarestorage.com',
              aws_access_key_id=R2_ACCESS_KEY_ID,
              aws_secret_access_key=R2_SECRET_ACCESS_KEY
          )

          try:
              response = client.list_objects_v2(Bucket=R2_BUCKET_NAME)
              if 'Contents' in response:
                  print("Objects in bucket:")
                  for obj in response['Contents']:
                      print(obj['Key'])
              else:
                  print("Bucket is empty.")
          except ClientError as e:
              print("Error accessing bucket:", e)
          EOF
